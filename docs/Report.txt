1.
Given that:
	- T is a set of timeslots
	- R is a set of rooms
	- S is a set of student classes 
	- W is a set of weekly classes
	- A is a set of associations
	- X is the set of variables
	- D is the set of domains for all variables
	- Di is the set of possible values (domain) for Xi

The variables in this problem are all the weekly classes (tuples) from every unique course in the associations set to which needs to be assigned a time slot and a room.
	X := W, e.g. X = {(IASD,T,1),(IASD,T,2),(SAut,T,1), ...}

For each variable, the domain is the set of all the possible combinations of room and time slot in the sets T and R.
	for all Xi in X
	Di = T x R, e.g. Di = {(Mon,8,EA1),(Mon,8,EA2),(Tue,8,EA1),...}

For every variable A, B and the respective assignement a, b there are 3 constraints: 
	- Each room can only hold one class at a time
		C1: (day(a), time(a), room(a)) != (day(b), time(b), room(b))

	- Each student class can only attend one class at a time
		C2: (course(A),time(a)) != (course(B),time(b))

	- No two weekly classes of the same course and type may occur on the same weekday
		C3: (course(A), type(A), day(a)) != (course(B), type(B), day(b))

The resulting constraint graph is a complete graph, with all nodes connecting to all other nodes by constraint C1 and connecting all nodes from the same course by C2 and also connecting all nodes of same course and same type by C3.

2. 
We performed several tests in order to evaluate the performance of the CSP problem solver under different heuristics. The performance was measured by timing the execution in datasets of different complexity.

When selecting an inference we had 3 choices: no inference, Forward Checking (FC) and Maintaining Arc Consistency (MAC). We found that propagating constraints gave better results than not applying. Given the high density of our constraint graph, when applying FC, an assignement would be propagated through all the graph. For MAC, propagating the assignement recursively through the graph was too slow and not worth the effort.

When selecting the next variable to assign we use the Minimum Remaining Values (MRV) heuristic to choose the variable whose domain is the smallest. This way branching is reduced and therefore so is the time complexity of the search problem.

When assigning a value we use the Least Constraining Value (LCV) which tries to keep the neighbor's domains as broad as possible, in order to find a solution faster.

We found that for well-structured datasets (in which the timeslots are similar for different days - e.g. Mon,8 Mon,9 Tue,8 Tue,9 Wed,8 ...), the quickest way to solve was to sort the domains by ascending timeslot (Mon,8 Tue,8 Wed,8 Mon,9 Tue,9 ...) and then use only Forward Checking inference. This would result in assigning the first timeslots sequentially to classes of the same course and thus quickly making a fairly good assignement. For a complex dataset, it took about 9 seconds to solve using only FC and about 18 seconds using FC+MRV+LCV.

This heuristic of ordering the domains does not generalize well for datasets in which the domains are poorly structured (e.g. Mon,8 Mon,9 Tue,15 Tue,16 Wed,22 Wed,23 Thu,200 Thu,201 ...) in which our dataset could not be solved in less than 2 minutes using only FC. In this case applying FC+MRV+LCV resulted in an execution time of 19.4 seconds, roughly the same time as in a "well-behaved" dataset.

Because of the robustness properties in different types of datasets, we decided to perform backtrack search combining FC+MRV+LCV.

Also note that, for the simple datasets, like the ones in the public tests, applying MRV and LCV heuristics was slower simply because of the computational effort of comparing the variables and their possible values. The Forward Checking inference was still worth applying.